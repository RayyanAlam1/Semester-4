{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"id":"JFJ4kNvhISjM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715752285730,"user_tz":-300,"elapsed":448,"user":{"displayName":"Usama Antuley","userId":"14366497336481635482"}},"outputId":"699237c3-9ba7-4735-ae3d-8922bb16bc47"},"outputs":[{"output_type":"stream","name":"stdout","text":["|   Iteration | theta                         |        J | Partial derivatives         |\n","|-------------|-------------------------------|----------|-----------------------------|\n","|           1 | [0.0, 0.0]                    | 12.8333  | [ -5.         -30.66666667] |\n","|           2 | [0.05, 0.3066666666666667]    |  4.99629 | [ -3.11       -19.12222222] |\n","|           3 | [0.0811, 0.49788888888888894] |  1.94951 | [ -1.93156667 -11.92414074] |\n"]}],"source":["from tabulate import tabulate\n","import numpy as np\n","\n","def gradient_descent(x, y, alpha, num_iters):\n","    m = y.size  # number of training examples\n","    theta = np.zeros(2)  # initialize parameters to zero\n","    data = []  # keep track of cost function values\n","    for i in range(num_iters):\n","        # Calculate hypothesis and cost function\n","        h = X.dot(theta)\n","        J = np.sum((h - y) ** 2) / (2 * m)\n","        partial_derivatives = X.T.dot(h - y) / m\n","        data.append([i+1, list(np.copy(theta)), J, partial_derivatives])  # Convert theta to a list\n","        # Update parameters\n","        theta -= alpha / m * (X.T.dot(h - y))\n","\n","    # Print table of parameter values and partial derivatives of J outside the loop\n","    print(tabulate(data, headers=['Iteration', 'theta', 'J', 'Partial derivatives'], tablefmt='github'))\n","\n","# Generate some example data points\n","x = np.array([5, 6, 7])\n","y = np.array([4, 5, 6])\n","\n","# Add a column of ones for the intercept term\n","X = np.vstack((np.ones(x.size), x)).T\n","\n","# Set the learning rate and number of iterations\n","alpha = 0.01\n","gradient_descent(x, y, alpha, 3)\n"]}]}